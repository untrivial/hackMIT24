{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tqdm \n",
    "from openai import OpenAI\n",
    "\n",
    "from pinecone import Pinecone\n",
    "\n",
    "from langchain.graphs import Neo4jGraph\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import StorageContext\n",
    "\n",
    "from langchain_community.graphs.graph_document import (\n",
    "    Node as BaseNode,\n",
    "    Relationship as BaseRelationship,\n",
    "    GraphDocument,\n",
    ")\n",
    "from langchain.schema import Document\n",
    "from typing import List, Dict, Any, Optional\n",
    "from langchain.pydantic_v1 import Field, BaseModel\n",
    "from langchain.chains import GraphCypherQAChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(dotenv_path='secrets.env')\n",
    "graph = Neo4jGraph(\n",
    "    url=os.environ[\"NEO4J_URI\"],\n",
    "    username=os.environ[\"NEO4J_USERNAME\"],\n",
    "    password=os.environ[\"NEO4J_PASSWORD\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('dataset.csv')\n",
    "# df.head()\n",
    "track_id_list = df['track_id']\n",
    "track_artists_list = df['artists']\n",
    "track_name_list = df['track_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize Pinecone\n",
    "api_key = os.environ['PINECONE_API_KEY']\n",
    "environment = os.environ['PINECONE_ENVIRONMENT']\n",
    "pinecone = Pinecone(api_key=api_key, environment=environment)\n",
    "\n",
    "index_name = \"cos-15\"\n",
    "pinecone_index = pinecone.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         73\n",
      "1         55\n",
      "2         57\n",
      "3         71\n",
      "4         82\n",
      "          ..\n",
      "113995    21\n",
      "113996    22\n",
      "113997    22\n",
      "113998    41\n",
      "113999    22\n",
      "Name: popularity, Length: 114000, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['popularity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize relevant columns\n",
    "# popularity\tduration_ms\texplicit\tdanceability\tenergy\tkey\tloudness\tmode\n",
    "# \tspeechiness\tacousticness\tinstrumentalness\tliveness\tvalence\ttempo\ttime_signature\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# df['popularity_normalized'] = scaler.fit_transform(df[['popularity']])\n",
    "df['duration_ms_normalized'] = scaler.fit_transform(df[['duration_ms']])\n",
    "df['explicit_normalized'] = scaler.fit_transform(df[['explicit']])\n",
    "df['danceability_normalized'] = scaler.fit_transform(df[['danceability']])\n",
    "df['energy_normalized'] = scaler.fit_transform(df[['energy']])\n",
    "df['key_normalized'] = scaler.fit_transform(df[['key']])\n",
    "df['loudness_normalized'] = scaler.fit_transform(df[['loudness']])\n",
    "df['mode_normalized'] = scaler.fit_transform(df[['mode']])\n",
    "df['speechiness_normalized'] = scaler.fit_transform(df[['speechiness']])\n",
    "df['acousticness_normalized'] = scaler.fit_transform(df[['acousticness']])\n",
    "df['instrumentalness_normalized'] = scaler.fit_transform(df[['instrumentalness']])\n",
    "df['liveness_normalized'] = scaler.fit_transform(df[['liveness']])\n",
    "df['valence_normalized'] = scaler.fit_transform(df[['valence']])\n",
    "df['tempo_normalized'] = scaler.fit_transform(df[['tempo']])\n",
    "df['time_signature_normalized'] = scaler.fit_transform(df[['time_signature']])\n",
    "# If you want to replace the original column instead of creating a new one, use:\n",
    "# df['popularity'] = scaler.fit_transform(df[['popularity']])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPSERT\n",
    "to_upsert = []\n",
    "\n",
    "# iterate through the df\n",
    "for index, row in df.iterrows():\n",
    "    values = [row['popularity_normalized'],\n",
    "              row['duration_ms_normalized'],\n",
    "              row['explicit_normalized'],\n",
    "              row['danceability_normalized'],\n",
    "              row['energy_normalized'],\n",
    "              row['key_normalized'],\n",
    "              row['loudness_normalized'],\n",
    "              row['mode_normalized'],\n",
    "              row['speechiness_normalized'],\n",
    "              row['acousticness_normalized'],\n",
    "              row['instrumentalness_normalized'],\n",
    "              row['liveness_normalized'],\n",
    "              row['valence_normalized'],\n",
    "              row['tempo_normalized'],\n",
    "              row['time_signature_normalized']\n",
    "    ]\n",
    "    data = {\n",
    "        'id': row['track_id'],\n",
    "        'values': values,\n",
    "        'metadata': {\n",
    "            'track_name': row['track_name'],\n",
    "            'artists': row['artists']\n",
    "        }\n",
    "    }\n",
    "    to_upsert.append(data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10\n",
    "for i in tqdm(range(0, len(to_upsert), batch_size), desc=\"Upserting batches\"):\n",
    "    batch = to_upsert[i:i + batch_size]\n",
    "    pinecone_index.upsert(vectors=batch, namespace=\"relationship-types\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Property(BaseModel):\n",
    "    key: str = Field(..., description=\"key\")\n",
    "    value: str = Field(..., description=\"value\")\n",
    "\n",
    "class Node(BaseNode):\n",
    "    properties: Optional[List[Property]] = Field(None, description=\"node properties\")\n",
    "\n",
    "class Relationship(BaseRelationship):\n",
    "    properties: Optional[List[Property]] = Field(None, description=\"relationship properties\")\n",
    "\n",
    "class KnowledgeGraph(BaseModel):\n",
    "    nodes: List[Node] = Field(..., description=\"nodes in the graph\")\n",
    "    rels: List[Relationship] = Field(..., description=\"relationships in the graph\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16a6337c-f844-4434-95ea-09f4c89f710a\n"
     ]
    }
   ],
   "source": [
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = [] # str list\n",
    "nodeTopK = [] # list of lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add every node to the graph database\n",
    "for nodeName in nodes:\n",
    "    query = (\n",
    "        f\"CREATE (n:{nodeName} {{name: '{nodeName}'}})\"\n",
    "    )\n",
    "    graph.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to add a node to the Neo4j graph\n",
    "def add_node_to_graph(nodeName: str, trackId: str, artists: str):\n",
    "    # Create a dictionary of properties\n",
    "    query = (\n",
    "        f\"CREATE (n:Track {{ name: '{nodeName}', id: '{trackId}', artists: '{artists}' }})\"\n",
    "    )\n",
    "    # run Node query\n",
    "    graph.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_node_to_graph(\"test1\", \"testId1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete a specific node\n",
    "def delete_node_from_graph(node_id: str):\n",
    "    query = (\n",
    "        f\"MATCH (n:Track {{id: '{node_id}'}}) \"\n",
    "        \"DETACH DELETE n\"\n",
    "    )\n",
    "    graph.query(query)\n",
    "\n",
    "# delete_node_from_graph(\"testId1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete all nodes\n",
    "def delete_all_nodes():\n",
    "    query = (\n",
    "        \"MATCH (n) \"\n",
    "        \"DETACH DELETE n\"\n",
    "    )\n",
    "    graph.query(query)\n",
    "\n",
    "# Uncomment the following line to execute the deletion\n",
    "delete_all_nodes()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "114000\n"
     ]
    }
   ],
   "source": [
    "print(len(track_id_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 / 114000\n",
      "100 / 114000\n",
      "200 / 114000\n",
      "300 / 114000\n",
      "400 / 114000\n",
      "500 / 114000\n",
      "600 / 114000\n",
      "700 / 114000\n",
      "800 / 114000\n",
      "900 / 114000\n",
      "1000 / 114000\n",
      "1100 / 114000\n",
      "1200 / 114000\n",
      "1300 / 114000\n",
      "1400 / 114000\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(track_id_list)):\n",
    "    if i % 100 == 0:\n",
    "        print(i, \"/\", len(track_id_list))\n",
    "    try:\n",
    "        add_node_to_graph(track_name_list[i], track_id_list[i], track_artists_list[i])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spotify idea\n",
    "- build a graph of songs / artists that can do recommendation engines\n",
    "# predev replication\n",
    "- build a knowledge graph for planning a full stack website\n",
    "\n",
    "# frontend\n",
    "- text box\n",
    "- Graph visualization in JavaScript"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
